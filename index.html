<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>FaceCam</title>
    <script src="js/face-api.js"></script>
    <style>
        input[type=number]::-webkit-inner-spin-button, input[type=number]::-webkit-outer-spin-button { 
            -webkit-appearance: none; 
        }
    </style>
</head>

<body>
    <label>Upload Image:</label> <input type="file" onchange="uploadImage(event)" accept=".jpg, .jpeg, .png">
    <label>Threshold:</label><input id="threshold" style="-webkit-appearance:none;" type="number" value=".30" step="0.01" min=".01" max="1.00">
    <label>maxDiff:</label><input id="maxDiff" style="-webkit-appearance:none;" type="number" value=".60" step="0.01" min=".01" max="1.00">
    Status: <span id="status"></span>
    <div id="imagediv">
        <img id="myImg" src="bbt1.jpg" alt="" style="max-width: 800px;">
    </div>
    <script>
    var labeledFaceDescriptors = [];
    var faceMatcher = null;
    var threshold = .3;
    var maxDiff = .6;

    function clearFaceNames() {
        let paras = document.getElementsByClassName('faceNames');
        while (paras[0]) {
            paras[0].parentNode.removeChild(paras[0]);
        }
    }

    function drawFaceRecognitionResults(results) {
        clearFaceNames()
        inputImgEl = document.getElementById("myImg");
        results = faceapi.resizeResults(results, inputImgEl);

        results.forEach(function(result) {
            let btn = document.createElement("button");
            if (result.bestMatch.label != 'unknown') {
                btn.innerText = result.bestMatch.label;
            } else {
                btn.innerText = result.age.toFixed(0) + ' year old ' + result.expressions.asSortedArray()[0].expression + ' ' + result.gender;
            }
            btn.title = (100 * (1 - result.bestMatch.distance)).toFixed(0) + ' %';
            btn.style.position = 'absolute';
            btn.style.top = result.detection.box.top + 'px';
            btn.style.left = result.detection.box.left + 'px';
            btn.className = 'faceNames';
            btn.dataset.person = result.bestMatch.label;
            btn.dataset.descriptor = result.descriptor;
            btn.addEventListener("click", personClick);
            document.getElementById("imagediv").appendChild(btn);
        })
    }

    function makeFaceMatcher() {
        if (labeledFaceDescriptors.length > 0) {
            faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDiff);
        }
    }

    function addDescriptor(newPerson, descriptor) {
        for (let i = 0; i < labeledFaceDescriptors.length; i++) {
            if (labeledFaceDescriptors[i].label == newPerson) {
                labeledFaceDescriptors[i].descriptors.push(new Float32Array(descriptor.split(',')));
                makeFaceMatcher();
                return;
            }
        }
        descriptors = [];
        descriptors.push(new Float32Array(descriptor.split(',')));
        labeledFaceDescriptors.push(new faceapi.LabeledFaceDescriptors(newPerson, descriptors));
        makeFaceMatcher();
    }

    function personClick(e) {
        var newPerson = prompt("Please enter person's name:", e.target.dataset.person);
        if (newPerson == null || newPerson == "" || newPerson == "unknown") {} else {
            e.target.dataset.person = newPerson;
            e.target.innerHTML = newPerson;
            addDescriptor(newPerson, e.target.dataset.descriptor);
            updateResults();
        }
    }
    async function loadModels() {
        console.time('loadModels')
        updateStatus('loadModels');
        //let weightsURI = "weights";
        let weightsURI = "https://seattleacademy.github.io/faceRoster/weights";
        updateStatus('ssdMobilenetv1');
        await faceapi.nets.ssdMobilenetv1.load(weightsURI);
        updateStatus('faceLandmark68Net');
        await faceapi.nets.faceLandmark68Net.load(weightsURI);
        updateStatus('faceExpressionNet');
        await faceapi.nets.faceExpressionNet.load(weightsURI);
        updateStatus('ageGenderNet');
        await faceapi.nets.ageGenderNet.load(weightsURI);
        updateStatus('faceRecognitionNet');
        await faceapi.nets.faceRecognitionNet.loadFromUri(weightsURI)
        console.timeEnd('loadModels')
    }

    async function updateResults() {
        console.time('updateResults')
        updateStatus('upateResults');
        let options = new faceapi.SsdMobilenetv1Options({ minConfidence: Number(threshold) })
        results = await faceapi.detectAllFaces("myImg", options).withFaceLandmarks().withFaceExpressions().withAgeAndGender().withFaceDescriptors();

        results.forEach(function(result, i, results) {
            if (faceMatcher) {
                results[i].bestMatch = faceMatcher.findBestMatch(result.descriptor)
            } else {
                results[i].bestMatch = new faceapi.FaceMatch('unknown', 1);
            }
        })

        drawFaceRecognitionResults(results);
        updateStatus('');
        console.timeEnd('updateResults')
    }

    async function uploadImage(e) {
        const imgFile = e.target.files[0]
        const img = await faceapi.bufferToImage(imgFile)
        document.getElementById("myImg").src = img.src
        updateResults();
    }

    function updateStatus(str) {
        document.getElementById("status").innerHTML = str;
    }

    document.getElementById('threshold').addEventListener('change', function(event) {
        threshold = event.target.value;
        makeFaceMatcher();
        updateResults();
    }, false);

    document.getElementById('maxDiff').addEventListener('change', function(event) {
        maxDiff = event.target.value;
        makeFaceMatcher();
        updateResults();
    }, false);

    loadModels().then(updateResults);
    </script>
</body>

</html>